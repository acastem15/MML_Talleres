{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN/HnLYmmWMnDWpWCdTyGOw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Mastering Machine Learning 2025\n","\n","Taller 2: tokenizers y embeddings\n","\n","Antes de iniciar abra este cuaderno en Google Colab y habilite la ejecución con GPU:\n","- En el menú Entorno de ejecución seleccione Cambiar tipo entorno de ejecución.\n","- Asegúrese de tener seleccionado Python 3.\n","- Como Acelerador de hardware seleccione GPU T4."],"metadata":{"id":"HaxuXP_zdmAv"}},{"cell_type":"markdown","source":["Instale las dependencias para asegurar la correcta ejecución del cuaderno."],"metadata":{"id":"Mh_ogQDueaYj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSDm6VmFGvot"},"outputs":[],"source":["!pip install --upgrade transformers==4.41.2 sentence-transformers==3.0.1 gensim==4.3.2 scikit-learn==1.5.0 accelerate==0.31.0 peft==0.11.1 scipy==1.10.1 numpy==1.26.4"]},{"cell_type":"markdown","source":["## Generar texto con prompts y tokens"],"metadata":{"id":"qC9vFNLimpjl"}},{"cell_type":"markdown","source":["Ahora usaremos la librería transformers de Hugging Face. Puede crear una cuenta en https://huggingface.co/\n","\n","Importamos las clases para el tokenizador y el modelo de lenguaje Phi-3-Mini-4K-Instruct, disponible en Hugging Face."],"metadata":{"id":"1ffv3mn-evug"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# Cargamos el modelo\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"microsoft/Phi-3-mini-4k-instruct\",\n","    device_map=\"cuda\",\n","    torch_dtype=\"auto\",\n","    trust_remote_code=False,\n",")\n","\n","# Cargamos el tokenizador\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"],"metadata":{"id":"xWPVdgCWHCyz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ejecutemos un prompt solicitando un correo"],"metadata":{"id":"CTcnhG4sipqt"}},{"cell_type":"code","source":["# Prompt a ejecutar\n","prompt = \"Write an email to authorize the entrance of King William to the University.<|assistant|>\"\n","\n","# Tokenizar el prompt de entrada - retorna tensores de pytorch - los tipos de datos son compatibles con CUDA\n","input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n","\n","# Generar el texto\n","generation_output = model.generate(\n","  input_ids=input_ids,\n","  max_new_tokens=40\n",")\n","\n","# Imprimir la salida (decodificada)\n","print(tokenizer.decode(generation_output[0]))"],"metadata":{"id":"4qoEErPVIm5p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Revisemos los tokens generados como entrada para el modelo, a partir del prompt"],"metadata":{"id":"5ZxAlbDYjLXr"}},{"cell_type":"code","source":["input_ids"],"metadata":{"id":"BbOSssUbJ0m-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Revisemos la traducción de tokens a texto (decode)"],"metadata":{"id":"acCFipdjjWi6"}},{"cell_type":"code","source":["for id in input_ids[0]:\n","   print(f'{id}: {tokenizer.decode(id)}')"],"metadata":{"id":"SCoZdC87J-yx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Revisemos la salida en formato token"],"metadata":{"id":"mnfAOilwjjQS"}},{"cell_type":"code","source":["generation_output"],"metadata":{"id":"XR2Nc2QpNHRT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veamos el tipo de dato de esta salida"],"metadata":{"id":"qyR-4j2Sjuc7"}},{"cell_type":"code","source":["generation_output[0][0]"],"metadata":{"id":"laLKz85FNLz8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veamos ahora la traducción de tokens a texto (decode)"],"metadata":{"id":"9AE6et0vj0kD"}},{"cell_type":"code","source":["for id in generation_output[0]:\n","   print(f'{id}: {tokenizer.decode(id)}')"],"metadata":{"id":"kMPTWgjMjoqk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Comparar tokenizadores"],"metadata":{"id":"NfBoMbFMkZWd"}},{"cell_type":"markdown","source":["Usaremos la siguiente función para ilustrar el resultado de la tokenización"],"metadata":{"id":"Zha1JeJFkHZS"}},{"cell_type":"code","source":["colors_list = [\n","    '102;194;165', '252;141;98', '141;160;203',\n","    '231;138;195', '166;216;84', '255;217;47'\n","]\n","\n","def show_tokens(sentence, tokenizer_name):\n","    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n","    token_ids = tokenizer(sentence).input_ids\n","    for idx, t in enumerate(token_ids):\n","        print(\n","            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n","            tokenizer.decode(t) +\n","            '\\x1b[0m',\n","            end=' '\n","        )"],"metadata":{"id":"oo2040InPSNg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usaremos este texto de prueba"],"metadata":{"id":"WSgHoCKOkP-z"}},{"cell_type":"code","source":["text = \"\"\"\n","\n","English and CAPITALIZATION\n","\n","🎵鸟\n","show_tokens False None elif == >= else: two tabs:\" \" Three tabs: \"   \"\n","\n","12.0*50=600\n","\n","\"\"\""],"metadata":{"id":"FINhKRKEQAAy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Inicialmente usaremos BERT en su versión uncased (2018)"],"metadata":{"id":"M68jicqRkXC0"}},{"cell_type":"code","source":["show_tokens(text, \"google-bert/bert-base-uncased\")"],"metadata":{"id":"6VkD_s4NRUVL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora usaremos BERT en su versión cased (2018)"],"metadata":{"id":"gZoEGgwzkikz"}},{"cell_type":"code","source":["show_tokens(text, \"google-bert/bert-base-cased\")"],"metadata":{"id":"rpguG_XaQCxy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora usamos GPT-2 (2019)"],"metadata":{"id":"qFjqotXrkpzt"}},{"cell_type":"code","source":["show_tokens(text, \"openai-community/gpt2\")"],"metadata":{"id":"LWSp2xQvTcoM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora usamos Flan-T5 (2022)"],"metadata":{"id":"mQZ2dqHHkwxU"}},{"cell_type":"code","source":["show_tokens(text, \"google/flan-t5-xxl\")"],"metadata":{"id":"sxY6kz5eToy0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora usamos StarCoder2 (2024)"],"metadata":{"id":"xFwagj0xk3uD"}},{"cell_type":"code","source":["show_tokens(text, \"bigcode/starcoder2-15b\")"],"metadata":{"id":"cloI_pgRT10b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora usamos Phi-3 que usamos al inicio y es similar al de Llama 2"],"metadata":{"id":"qnAjLJ35lAgs"}},{"cell_type":"code","source":["show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"],"metadata":{"id":"7TygHQVZUrrf"},"execution_count":null,"outputs":[]}]}