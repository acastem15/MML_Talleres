{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOpg6Kwa3QpHWbmsVd8UQ/6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Mastering Machine Learning 2025\n","\n","Taller 2: tokenizers y embeddings\n","\n","Antes de iniciar abra este cuaderno en Google Colab y habilite la ejecución con GPU:\n","- En el menú Entorno de ejecución seleccione Cambiar tipo entorno de ejecución.\n","- Asegúrese de tener seleccionado Python 3.\n","- Como Acelerador de hardware seleccione GPU T4."],"metadata":{"id":"ugp9xaoupCGr"}},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"id":"kE0BDpKHWbVj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Descarguemos un embedding entrenado con los datos de Wikipedia. El tamaño del vector del embedding es de 50 y tamaño de la descarga es cerca de 66MB.\n","\n","Puede encontrar otras opciones en https://github.com/RaRe-Technologies/gensim-data"],"metadata":{"id":"bwJxr1xfpLvI"}},{"cell_type":"code","source":["import gensim.downloader as api\n","\n","model = api.load(\"glove-wiki-gigaword-50\")"],"metadata":{"id":"fcBBYFktWFuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.most_similar([model['song']], topn=11)"],"metadata":{"id":"2VfW-zVWW-7W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Word2Vec para generar embeddings\n","\n","Word2Vec emplea contrastive learning, donde se comparan una palabra contra otra para determianr si pertenecen al mismo contexto o no. Se emplean ejemplos positivos (obtenidos del mismo texto) y negativos (obtenidos al azar)."],"metadata":{"id":"4rXnmhMeqEww"}},{"cell_type":"markdown","source":["Importamos las dependencias necesarias"],"metadata":{"id":"W0c4BcAMrrH-"}},{"cell_type":"code","source":["import pandas as pd\n","from urllib import request"],"metadata":{"id":"cCY4OPIFXCl7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cargamos los datos con un conjunto de datos de playlists"],"metadata":{"id":"vAglJko2ru6r"}},{"cell_type":"code","source":["data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')"],"metadata":{"id":"ePzX69J1r2KQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saltamos las dos primeras líneas ya que no tienen datos útiles para el ejercicio (solo metadatos)"],"metadata":{"id":"cEvkm6P-r8uu"}},{"cell_type":"code","source":["lines = data.read().decode(\"utf-8\").split('\\n')[2:]"],"metadata":{"id":"lQkdhkrBsN1H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Eliminamos playlists con una sola canción dado que no sirven para generar información del contexto en el que aparecen canciones similares (misma playlist)"],"metadata":{"id":"-OY8ktItsNSm"}},{"cell_type":"code","source":["playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]"],"metadata":{"id":"Zh_QlRt9sM0i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exploremos algunas de las playlists para ver su contenido (IDs de las canciones)"],"metadata":{"id":"B8ts91tBspI3"}},{"cell_type":"code","source":["print( f'Playlist #1:\\n {playlists[0]}\\n')\n","print( f'Playlist #2:\\n {playlists[1]}')"],"metadata":{"id":"P4otISYTXMmc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Importamos el modelo Word2Vec y lo entrenamos con el dataset de playlists"],"metadata":{"id":"R-qkwLdhs41F"}},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","model = Word2Vec(\n","    playlists, vector_size=32, window=20, negative=50, min_count=1, workers=4\n",")"],"metadata":{"id":"sHYCW_zHXSiP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Una vez entrenado, solocitamos canciones similares a una canción en particular"],"metadata":{"id":"P7WJWYa5tAvu"}},{"cell_type":"code","source":["song_id = 2172\n","\n","model.wv.most_similar(positive=str(song_id))"],"metadata":{"id":"UyUjrSFJXVMt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Traemos y procesamos los datos de las canciones para tener acceso a sus títulos y artistas"],"metadata":{"id":"JdT84tPgvPj4"}},{"cell_type":"code","source":["songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n","songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n","songs = [s.rstrip().split('\\t') for s in songs_file]\n","songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n","songs_df = songs_df.set_index('id')"],"metadata":{"id":"yI4WGru2vO7v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Traemos la información de la canción que seleccionamos"],"metadata":{"id":"T8XOAMoltJR7"}},{"cell_type":"code","source":["print(songs_df.iloc[song_id])"],"metadata":{"id":"qoqrWEO7XYT6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definimos una función para mostrar las canciones más similares a una seleccionada en formato texto"],"metadata":{"id":"BjkdlZtxtcw_"}},{"cell_type":"code","source":["import numpy as np\n","\n","def print_recommendations(song_id):\n","    similar_songs = np.array(\n","        model.wv.most_similar(positive=str(song_id),topn=5)\n","    )[:,0]\n","    return  songs_df.iloc[similar_songs]"],"metadata":{"id":"WzmHIREUXbVS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Empleamos la función creada con la canción seleccionada"],"metadata":{"id":"EKTDRWEwtnIg"}},{"cell_type":"code","source":["print_recommendations(song_id)"],"metadata":{"id":"k5RRYLDStmvf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["song_id = 2222\n","print(songs_df.iloc[song_id])\n","print_recommendations(song_id)"],"metadata":{"id":"lJvPHro7vp3B"},"execution_count":null,"outputs":[]}]}