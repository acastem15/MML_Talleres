{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugp9xaoupCGr"
   },
   "source": [
    "## Mastering Machine Learning 2025\n",
    "\n",
    "Taller 2: tokenizers y embeddings\n",
    "\n",
    "Antes de iniciar abra este cuaderno en Google Colab y habilite la ejecución con GPU:\n",
    "- En el menú Entorno de ejecución seleccione Cambiar tipo entorno de ejecución.\n",
    "- Asegúrese de tener seleccionado Python 3.\n",
    "- Como Acelerador de hardware seleccione GPU T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kE0BDpKHWbVj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\ascas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\ascas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.13.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/24.0 MB 871.5 kB/s eta 0:00:28\n",
      "   ---------------------------------------- 0.1/24.0 MB 1.1 MB/s eta 0:00:23\n",
      "    --------------------------------------- 0.4/24.0 MB 2.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.0/24.0 MB 5.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.1/24.0 MB 4.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.7/24.0 MB 5.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.0/24.0 MB 6.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.4/24.0 MB 6.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 7.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.4/24.0 MB 8.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.0/24.0 MB 8.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.3/24.0 MB 8.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/24.0 MB 8.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.1/24.0 MB 8.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.8/24.0 MB 8.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 6.7/24.0 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.1/24.0 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.3/24.0 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.8/24.0 MB 10.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.5/24.0 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.9/24.0 MB 10.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.7/24.0 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.4/24.0 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 11.7/24.0 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 12.1/24.0 MB 12.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 12.4/24.0 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 12.7/24.0 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.1/24.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.5/24.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.0/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.3/24.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.0/24.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.4/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.2/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.4/24.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 16.9/24.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.2/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.0/24.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.3/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.7/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.1/24.0 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.0 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.0/24.0 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.4/24.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.8/24.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.3/24.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.0 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.1/24.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.7/24.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.7/61.7 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.3 smart-open-7.1.0 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\ascas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwJxr1xfpLvI"
   },
   "source": [
    "Descarguemos un embedding entrenado con los datos de Wikipedia. El tamaño del vector del embedding es de 50 y tamaño de la descarga es cerca de 66MB.\n",
    "\n",
    "Puede encontrar otras opciones en https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fcBBYFktWFuU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2VfW-zVWW-7W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('song', 1.0),\n",
       " ('album', 0.9297007918357849),\n",
       " ('songs', 0.90098637342453),\n",
       " ('soundtrack', 0.8414768576622009),\n",
       " ('albums', 0.8228148221969604),\n",
       " ('pop', 0.8219155669212341),\n",
       " ('sings', 0.8201141357421875),\n",
       " ('tune', 0.8188669681549072),\n",
       " ('duet', 0.8186635971069336),\n",
       " ('remix', 0.8086214065551758),\n",
       " ('band', 0.8063263297080994)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([model['song']], topn=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rXnmhMeqEww"
   },
   "source": [
    "## Word2Vec para generar embeddings\n",
    "\n",
    "Word2Vec emplea contrastive learning, donde se comparan una palabra contra otra para determianr si pertenecen al mismo contexto o no. Se emplean ejemplos positivos (obtenidos del mismo texto) y negativos (obtenidos al azar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0c4BcAMrrH-"
   },
   "source": [
    "Importamos las dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCY4OPIFXCl7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAglJko2ru6r"
   },
   "source": [
    "Cargamos los datos con un conjunto de datos de playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePzX69J1r2KQ"
   },
   "outputs": [],
   "source": [
    "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEvkm6P-r8uu"
   },
   "source": [
    "Saltamos las dos primeras líneas ya que no tienen datos útiles para el ejercicio (solo metadatos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQkdhkrBsN1H"
   },
   "outputs": [],
   "source": [
    "lines = data.read().decode(\"utf-8\").split('\\n')[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OY8ktItsNSm"
   },
   "source": [
    "Eliminamos playlists con una sola canción dado que no sirven para generar información del contexto en el que aparecen canciones similares (misma playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh_QlRt9sM0i"
   },
   "outputs": [],
   "source": [
    "playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8ts91tBspI3"
   },
   "source": [
    "Exploremos algunas de las playlists para ver su contenido (IDs de las canciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4otISYTXMmc"
   },
   "outputs": [],
   "source": [
    "print( f'Playlist #1:\\n {playlists[0]}\\n')\n",
    "print( f'Playlist #2:\\n {playlists[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-qkwLdhs41F"
   },
   "source": [
    "Importamos el modelo Word2Vec y lo entrenamos con el dataset de playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHYCW_zHXSiP"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    playlists, vector_size=32, window=20, negative=50, min_count=1, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7WJWYa5tAvu"
   },
   "source": [
    "Una vez entrenado, solocitamos canciones similares a una canción en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyUjrSFJXVMt"
   },
   "outputs": [],
   "source": [
    "song_id = 2172\n",
    "\n",
    "model.wv.most_similar(positive=str(song_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdT84tPgvPj4"
   },
   "source": [
    "Traemos y procesamos los datos de las canciones para tener acceso a sus títulos y artistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI4WGru2vO7v"
   },
   "outputs": [],
   "source": [
    "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
    "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
    "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
    "songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n",
    "songs_df = songs_df.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8XOAMoltJR7"
   },
   "source": [
    "Traemos la información de la canción que seleccionamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoqrWEO7XYT6"
   },
   "outputs": [],
   "source": [
    "print(songs_df.iloc[song_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjkdlZtxtcw_"
   },
   "source": [
    "Definimos una función para mostrar las canciones más similares a una seleccionada en formato texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzmHIREUXbVS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_recommendations(song_id):\n",
    "    similar_songs = np.array(\n",
    "        model.wv.most_similar(positive=str(song_id),topn=5)\n",
    "    )[:,0]\n",
    "    return  songs_df.iloc[similar_songs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKTDRWEwtnIg"
   },
   "source": [
    "Empleamos la función creada con la canción seleccionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5RRYLDStmvf"
   },
   "outputs": [],
   "source": [
    "print_recommendations(song_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJvPHro7vp3B"
   },
   "outputs": [],
   "source": [
    "song_id = 2222\n",
    "print(songs_df.iloc[song_id])\n",
    "print_recommendations(song_id)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOpg6Kwa3QpHWbmsVd8UQ/6",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
